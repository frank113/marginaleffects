---
title: "Machine Learning"
---


`marginaleffects` offers several "model-agnostic" functions to interpret statistical and machine learning models. This vignette highlights how the package can be used to extract meaningful insights from the results of models trained using the `mlr3` and `tidymodels` frameworks.

The features in this vignette require version 0.16.0 or `marginaleffects`, or the development version which can be installed from Github:

```{r, eval = FALSE}
remotes::install_github("vincentarelbundock/marginaleffects")
```

Make sure to restart `R` after installation. Then, load a few libraries:

```{r}
#| message: false
#| warning: false
library("marginaleffects")
library("fmeffects")
library("ggplot2")
library("mlr3verse")
library("tidymodels") |> suppressPackageStartupMessages()
options(width = 10000)
```
```{r}
#| include: false
pkgload::load_all()
```

## `mlr3`

`mlr3` is a machine learning framework for `R`. It makes it possible for users to train a wide range of models, including linear models, random forests, gradient boosting machines, and neural networks.

In this example, we use the `bikes` dataset supplied by the `fmeffects` package to train a random forest model predicting the number of bikes rented per hour. We then use `marginaleffects` to interpret the results of the model.

```{r}
data("bikes", package = "fmeffects")

task <- as_task_regr(x = bikes, id = "bikes", target = "count")
forest <- lrn("regr.ranger")$train(task)
```

As described in other vignettes, we can use the `avg_comparisons()` function to compute the average change in predicted outcome that is associated with a change in each feature:

```{r}
avg_comparisons(forest, newdata = bikes)
```
```{r}
#| include: false
cmp <- avg_comparisons(forest, newdata = bikes)
```

These results are easy to interpret: An increase of 1 degree Celsius in the temperature is associated with an increase of `r sprintf("%.3f", cmp$estimate[cmp$term == "temp"])` bikes rented per hour.

We could obtain the same result manually as follows:

```{r}
lo <- transform(bikes, temp = temp - 0.5)
hi <- transform(bikes, temp = temp + 0.5)
mean(predict(forest, newdata = hi) - predict(forest, newdata = lo))
```

As the code above makes clear, the `avg_comparisons()` computes the effect of a "centered" change on the outcome. If we want to compute a "Forward Marginal Effect" instead, we can call:

```{r}
avg_comparisons(
    forest,
    variables = list("temp" = \(x) data.frame(x, x + 1)),
    newdata = bikes)
```

This is equivalent to using the `fmeffects` package:

```{r}
fmeffects::fme(
    model = forest,
    data = bikes,
    target = "count",
    feature = "temp",
    step.size = 1)$ame 
```

With `marginaleffects::avg_comparisons()`, we can also compute the average effect of a simultaneous change in multiple predictors, using the `variables` and `cross` arguments. In this example, we see what happens (on average) to the predicted outcome when the `temp`, `season`, and `weather` predictors all change together: 

```{r}
avg_comparisons(
    forest,
    variables = c("temp", "season", "weather"),
    cross = TRUE,
    newdata = bikes)
```


```{r}
plot_predictions(forest, condition = "temp")
```

# tidymodels

`marginaleffects` also supports the `tidymodels` machine learning framework. When the underlying engine used by `tidymodels` to train the model is itself supported as a standalone package by `marginaleffects`, we can obtain estimates of uncertainty estimates:

```{r, message = FALSE}
#| warning: false
suppressPackageStartupMessages(library(tidymodels))
mod <- linear_reg(mode = "regression") |>
    set_engine("lm") |>
    fit(count ~ ., data = bikes)
avg_comparisons(mod, newdata = bikes, type = "response")
```

We can also plot the results as usual:

```{r, warning = FALSE}
plot_predictions(mod, condition = "temp", points = .2)
```

When the underlying engine that `tidymodels` uses to fit the model is not supported by `marginaleffects` as a standalone model, we can also obtain correct results, but no uncertainy estimates. Here is a random forest model:

```{r}
forest_tidy <- rand_forest(mode = "regression") |>
    set_engine("ranger") |>
    fit(count ~ ., data = bikes)
avg_comparisons(forest_tidy, newdata = bikes, type = "numeric")

plot_predictions(forest_tidy, newdata = bikes, by = "temp", type = "numeric")
```
